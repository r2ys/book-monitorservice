{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 企业应用统一监控告警方案 前言 本文从以下出发点入手，旨在针对所有业务系统、中台服务、基础服务等制定统一的监控告警标准。 监控维度 业务监控 链路监控 应用监控 容器和主机监控 统一监控告警系统设计 需求调研 如何建设生产环境下的系统可观测性能力 监控报警是业务系统的金钟罩，对业务系统非常重要。不存在不出问题、没有 Bug 的系统。系统上线之后，就免 不了出现故障，出故障是或早或晚的事，是或多或少的事。我们能做的是，出现故障之后，第一时间知道，赶紧处理，防止影响扩大。再理想点，如果故障出现之前，刚有苗头的时候，我们就能发现，提前解决就更好了。业务系统的监控报警，就是干这个用的。 通常来说一个没有监控的系统，在运行期间对问题的反馈通常是这个流程： 线上bug反馈：用户-客服-产品负责人/项目负责人-开发 如何做到快速发现bug/如何做到出现之前就发现 举一个简单的业务调用的例子： 三方响应时间预期是2秒，程序设置超时时间是5s，通过对响应时间进行监控，在接近5秒时就主动预警，通过联系下游渠道解决，就杜绝了超时之后告警的问题。 目标 监控和告警的目标则是一致的，即： 全面：监控与告警的广度，尽可能多的覆盖到故障类型 及时：数据处理和传递的时效性，快速的将告警信息暴露出来 准确：保证监控和告警信息的准确性，避免浪费相应的资源去解决错误的告警。 附录 参考文档： 基于Telegraf Influxdb Grafana的监控平台介绍 Telegraf开源组件 cAdvisor InfluxDB Grafana搭建监控平台 基于Telegraf的数据收集系统 使用Prometheus+Grafana快速打造高逼格监控平台 Telegraf 使用 指标与日志的监控告警系统设计 一篇文章了解监控告警 如何专业化监测一个 Kubernetes 集群？ 接口链路统计 阿里云ARMS链路监控 浅谈全链路监控 Prometheus学习 阿里云应用实时监控服务ARMS产品文档 Micrometer 快速入门 Spring Boot 使用 Micrometer Prometheus 监控埋点 Prometheus Prometheus中文文档 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"metrics/root.html":{"url":"metrics/root.html","title":"监控维度","keywords":"","body":"监控维度 针对当前企业应用分布，我们主要针对以下维度进行性能指标数据的收集： 物理机HostOS 容器、k8s 中间件：数据库(自建/云)[mysql、redis、mongodb、oracle] 负载: Nginx、LB、云负载 应用：健康检查、应用容器[tomcat、undertow]、服务实例监控 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"metrics/":{"url":"metrics/","title":"监控指标","keywords":"","body":"监控指标 监控指标从各个维度配置： 主机： cpu使用率 内存使用率 IO速率 磁盘空间 服务 响应时间 错误率 请求比例 并发数 延迟率 事务处理 应用 前端页面：响应时间、加载时间 性能：响应时间、成功/失败数 健康度：告警量 监控信息汇总示意图 监控维度的分类参考图 指标管理 如何建立完善、全面、直观的指标体系。指标拆解的维度和粒度？ 从指标的定位上区分： 指标类型参考示例 容器监控指标(docker/kubernetes) 客户机监控指标(GuestOS) VMware Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"biz/root.html":{"url":"biz/root.html","title":"业务监控","keywords":"","body":"业务监控 背景 业务系统类似飞机，我们应该关注服务及业务的运行情况，而且通常来说，后台开发负责的是在快速飞行的飞机上修零件；边飞边升级。所以就像飞机仪表盘时刻指示着各个模块的运行情况，我们业务系统都应该有自己的仪表盘-业务监控告警。 目标 我们希望通过业务监控告警保证我们的业务和服务的可靠性，最终达到如下的效果： 我们要能够及时的发现问题（先于客户、运营发现问题）。 不想每天半夜爬起来处理不知道怎么来的问题（有一些事情准备）。 出了问题，能够帮助我们，快速定位问题。 问题点 关注点 站在业务角度，一个业务服务经常关注的点有如下： 机器系统资源(CPU/内存/网络/磁盘)、CDN等 JVM虚拟机运行情况 接口的调用量、耗时情况、错误异常 具体业务（如注册、开户、交易等流程） 具体运营 相关指标梳理参考 如何从监控数据定义异常 通常来讲，每天同一时间的监控数值应当一致。基于这个依据，我们可以做一些比较以发现问题。 同比：当前时间跟昨天同一时刻进行比较，是上升还是下降。 用于突然的掉底或上升问题发现。 环比：当前一段时间与前一段时间比较，一般用得比较少。 七日平均值：当前时间与前七天同一时刻平均值进行同比。减少某天波动带来的影响。 异常发现时间 综合成本以及时效性的权衡，一大部分采用实时监控，部分需要综合比较监控数据的情况采用隔日处理 实时监控处理：强调实时性，针对关键节点、存在少量数据不一致或丢失情况。 隔日处理：有充足的资源、全量节点、数据准确、利用大数据能力。 如何在代码中自定义异常 通常的方式是定义切入点，埋入不影响业务运行的代码片，异步输出。 通过接口层、业务逻辑层、数据库层、包括下游渠道层做埋点，手动捕捉异常并输出。 针对其他关注点执行特殊异常处理，最终输出。 异常程度 异常分级处理： 忽略：一些可以忽略的数据波动，影响比较小的、不紧急的情况。这类可忽略的异常通常是某些告警异常的前奏。 通知：提醒负责人该关注一下这里的问题，视情况而处理，比如账户余额、交易量上升等。这部分是需要权衡的，如果一些比较关注的点发出通知，比如可接受的交易成功率出现比较大的下滑、或某些交易接口请求量上升的时候就可以人工介入。 告警：出现比较大的问题了，需要安排人力紧急排查了。 通知 跟上面异常程度相对应，有不同的告警方式通知关注者。 紧急程度依次是：数据图表 数据图表：对应忽略、通知 微信：对应通知 短信/电话：对应告警 如何做到既减少骚扰又能及时发现问题： 做到高内聚低耦合，暴露给外部是最简单的 精细化处理某些点，根据场景采取不同策略 收到告警后的处理 很多时候收到通知或告警后难定位问题，这个时候凸显出监控数据图表的重要性，可结合图表分析问题。 如何处理 1 业务初期的简单处理 业务或系统的初期，没有人力去做，但监控告警是必要的，此时可以确认关键点，根据数据库记录，做统计和分析。 定时扫描订单数据库统计同比； 根据确定波动阈值告警 2 业务平稳后的计算统计 针对全量扫表的性能问题，需要将监控告警独立成单独的模块。 将小粒度的实时统计数据保存到统计数据库； 跑批对比分析同比数据； 3 日志收集分析系统 利用公用的监控告警系统，将业务关注的点通过抽象行为日志上报给代理日志中心，大数据中心做数据分析和存储。 定义需要统计的节点的维度、度量、原始数据留存时间。 业务系统上报日志或输出日志 代理日志中心将日志数据临时存储、再同步到大数据中心。 大数据中心根据节点、统计维度、度量、统计时间做交叉数据统计。 根据交叉数据做实时监控告警。 根据明细数据做全量数据报表。 业务监控功能需求概况 有别于硬件、应用监控，业务监控应当从业务语义指标去衡量应用健康度，能直观地体现例如当日下单平均响应时间、成功率等业务问题。意味着从业务视角衡量应用性能和稳定性，对业务的关键交易进行全链路的监控。业务监控通过追踪并采集应用程序中的业务信息，实时展现业务级的指标，例如业务的响应时长、次数和错误率，最终将应用程序和业务表现之间做映射关联。 业务监控的实现方式 理想的方式是应用探针： 监控方式 接入成本 实时性 灵活性 业务监控（应用探针） 低（业务信息在应用程序中自动采集上报） 实时（后台实时聚合运算展现） 高（灵活配置业务映射规则，立即生效） 自定义监控（日志） 高（需要改造应用程序，在日志中打印业务信息） 实时 低（新增的分析需求需要更改日志后才能展示业务信息） 传统OLAP BI分析 高（为避免影响在线业务处理性能，需要新建离线分析数据库，定期同步数据） 非实时（由于数据同步的间隔，无法实时分析） 中（取决于同步的业务数据是否齐全） 可视化业务规则配置 以无侵入方式可视化定义业务请求 通常在HTTP请求的Header、 请求参数和Session中，或者在RPC调用的请求参数中都包含有业务信息，例如订单金额、用户名称、用户属性、业务动作和来源等。 业务监控通过Java Agent的方式，实时采集这些业务信息，连带相应的URL和接口名等信息一同上报。 可以在业务监控的控制台，通过可视化界面灵活地定义某个业务信息与URL、RPC接口的映射关系，包括需要匹配的信息和拆分的维度， 完成业务与服务调用的关联。 参考阿里云ARMS的规则配置能力： 贴合业务的性能指标与诊断能力 业务监控默认提供某一业务的应用链路拓扑，以及吞吐量、响应时间和错误率等指标，同时可以关联到相应的数据库请求、异常和各级调用链路。 参考阿里云ARMS的业务监控指标诊断能力： Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"trace/root.html":{"url":"trace/root.html","title":"链路监控","keywords":"","body":"链路监控 背景 微服务架构下，服务间的链路关系可能是单向，也可以是网状的。调用链的链路监控能帮助快速定位异常产生的服务点。涵盖前端->services->db等 上报应用调用信息的需求是对应用无侵入、异步高性能。 微服务的治理应该从设计开始就启动，将微服务应用通过无侵入的方式接入，构建一体化的全链路监控体系。避免后期对生产故障的定位费尽周折。 链路监控负责的职责通常包含全链路监控与应用性能管理。 链路监控应当提供分布式应用下完整的调用链路还原、调用请求量统计、链路拓扑、应用依赖分析，可以帮助开发者快速分析和诊断分布式应用架构下的性能瓶颈，提高微服务时代下的开发诊断效率。 链路跟踪的目标 对系统的监控最终目标都是能第一时间发现问题、定位问题、解决问题。 而调用链监控的诉求是可以清晰梳理整套系统的调用关系，并评判应用上下游依赖的合理性，同时了解每一个应用的性能指标，并对系统容量进行合理的规划，不论分布式系统哪个节点出现故障或异常都可以实时反馈。 链路监控功能需求 分布式调用链查询和诊断：追踪分布式架构中的所有微服务用户请求，并将它们汇总成分布式调用链。 应用性能实时汇总：通过追踪整个应用程序的用户请求，来实时汇总组成应用程序的单个服务和资源。 分布式拓扑动态发现：用户的所有分布式微服务应用和相关PaaS产品可以通过链路追踪收集到分布式调用信息。 多语言开发程序接入：基于OpenTracing标准，全面兼容开源社区，例如Jaeger、Zipkin。 丰富的下游对接场景：收集的链路可直接用于日志分析，且可对接到MaxCompute等下游分析平台。 链路监控工作流程 客户侧的应用程序通过集成链路追踪的多语言客户端SDK上报服务调用数据。链路追踪支持多种开源社区的SDK，且支持OpenTracing标准。 数据上报至链路追踪控制台后，链路追踪组件进行实时聚合计算和持久化，形成链路明细、性能总览、实时拓扑等监控数据。您可以据此进行问题排查与诊断。 调用链数据可对接下游产品，例如LogSearch、CloudMonitor、MaxCompute等，用于离线分析、报警等场景。 链路监控架构 链路追踪技术 特性 低侵入性：业务无侵入，使用方透明，接入极简 性能无影响：目标是客户系统cpu占用2%以下；优先推荐agent方式，其次是业务系统埋点 接入简单、配置全面：尽可能降低接入成本，提供灵活的监控配置策略，动态配置收集数据的范围和粒度 监控展示实时有效：通过监控数据可以理解系统行为，为流程、架构、代码优化，以及扩容缩容、服务限流降级提供正确客观的数据参考。 技术细节 包括数据表示、埋点、传递、收集、存储与展示，核心概念有根据OpenTracing实现的跟踪树、Span、Trace、Annotation等。具体可参考谷歌早期的Dapper论文。优秀的全链路监控组件会尽可能的遵循OpenTracing标准，以获得更好的通用性以及扩展性。 OpenTracing 是一套统一的标准，让微服务体系中的所有应用遵循这套标准来实现跟踪信息的描述和传递，OpenTracing抽象出一套与编程语言以及业务逻辑无关的接口，对链路追踪领域各类元素的统一管理，保持对链路中每一个环节的记录与匹配，不仅在应用内部对跟踪信息进行传递，还让跟踪信息跨越不同的应用以及不同的分布式组件，从而实现完整的全链路监控。 客户端实现方式 业界的主流（非手动埋点）： SDK方式：通过引入链路追踪SDK自动生成链路数据，并自动上报。对于底层框架没有公开API的情况，监控逻辑的注入会比较复杂，有可能需要开发者针对具体的底层框架预先做好适配工作。 探针：不需要在代码编译前引入SDK，而是在应用运行的过程中，通过一个Agent动态的拦截底层框架的行为，从而自动注入监控逻辑。 采用探针的优点是不需要任何代码层面的改动，但并不是每一种编程语言都能提供探针机制，所以sdk方式也被很多全链路监控组件采用。 框架采集 信息采集依赖于链路追踪组件对于底层框架的识别。这些底层框架包含的领域非常广，其中包含： 应用对外提供服务所需要的框架 应用进程内部的通讯框架 应用之间相互访问所需要的框架 应用访问外部系统所需要的框架 java体系的范畴内包含： 用于提供HTTP服务的Tomcat、Jetty 用于进程内部通讯的RxJava 用于微服务应用之间相互调用的Feign 用于访问外部系统的MyBatis、MySQL JDBC、HTTPClient 对于多种编程语言以及种类繁多的底层框架的适配，是一项浩大的工程，一个全链路监控方案能够适配的底层框架越多，它的能力就越强大 数据收集后的处理 基础链路信息收集上来之后，需要进行统一存储，并对数据进行清洗与聚合，根据应用响应时间、请求数、错误率等指标进行下钻分析，并按应用、接口、链路、事务等多个维度进行展示。 技术方案比较【todo】 全链路监控方案的技术门槛非常高，在开源的全链路监控产品中，真正遵循OpenTracing标准，又够被广泛认可和使用的产品非常少，其中通过SDK方式接入的产品以Jaeger为代表，通过探针方式接入的产品以Skywalking为代表。 理想情况下，应当为每种语言的应用都提供sdk，支持多种数据库客户端。 zipkin pinpoint skywalking cat zipkin 通用方案是采用sleuth+zipking，支持多语言。 输入端点可以通过记录本地文件、输出stdout、输出到Syslog、或者通过接口上报。 通过写文件的方式，输入测采用filebeat、可视化使用zipkin/kibana，目的是组件公用 sleuth+zipking Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"app/root.html":{"url":"app/root.html","title":"应用监控","keywords":"","body":"应用监控 应用监控流程 应用的指标采集通常将Agent用于采集代码堆栈、资源利用、错误异常数据等，实现应用发现、应用拓扑生成、程序执行追踪等相关工作。 应用后端分析：应用性能管理产品接受采集的数据，对数据进行分类存储及分析处理； 系统管理：用户管理界面实现性能监控、故障诊断以及多维度数据统计分析。 实时告警 应用监控功能架构 应用拓扑：响应请求的执行过程、调用链路 外部服务 请求分析：包括吞吐率、响应耗时、响应状态、异常、错误率、缓慢率 数据库分析：包括数据库操作以及响应耗时 代码堆栈 后台任务 sql执行 错误&异常 应用探针颁发参考图 应用健康分析参考图： 拓扑监控参考图 请求分析参考图 请求堆栈分析 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"app/health.html":{"url":"app/health.html","title":"健康检查","keywords":"","body":"健康检查 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"app/jvm.html":{"url":"app/jvm.html","title":"jvm监控","keywords":"","body":"jvm监控 以java语言为例，关注的比较多的是jvm运行情况。 JVM 指标： 堆内存 heap_init：堆内存初始字节数 heap_max：堆内存最大字节数 heap_commited：堆内存提交字节数 heap_used：堆内存使用字节数 非堆内存 non_heap_init：非堆内存初始字节数 non_heap_max：非堆内存最大字节数 non_heap_commited：非堆内存提交字节数 non_heap_used：非堆内存使用字节数 直接缓冲区 direct_capacity：直接缓冲区总大小（字节） direct_used：直接缓冲区已使用大小（字节） 内存映射缓冲区 mapped_capacity：内存映射缓冲区总大小（字节） mapped_used：内存映射缓冲区已使用大小（字节） GC（垃圾收集）累计详情 GcPsMarkSweepCount：垃圾收集 PS MarkSweep 数量 GcPsScavengeCount：垃圾收集 PS Scavenge 数量 GcPsMarkSweepTime：垃圾收集 PS MarkSweep 时间 GcPsScavengeTime：垃圾收集 PS Scavenge 时间 JVM 线程数 ThreadCount：线程总数量 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"app/log.html":{"url":"app/log.html","title":"日志监控","keywords":"","body":"日志监控 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"hardware/root.html":{"url":"hardware/root.html","title":"容器和主机监控","keywords":"","body":"容器和主机监控 k8s监控 k8s的监控方案包括指标、日志、链路追踪、K8s Event 事件、NPD 框架等方式，每种方式可以从不同维度透视 Kubernetes 系统的状态和数据。 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/root.html":{"url":"architect/root.html","title":"统一监控告警系统设计","keywords":"","body":"统一监控告警系统设计 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/frame.html":{"url":"architect/frame.html","title":"框架选型","keywords":"","body":"[TOC] 框架选型 监控告警系统的流程主要分为四大部分，目前通用性强的开源方案由以下四部分组成： 采集 存储 可视化 日志监控 采集 Telegraf InfluxData公司提供了一整套包括采集、存储、展示、监控告警的解决方案：TICK STACK（Telegraf、InfluxDB、Chronograf、Kapacitor）。核心采集组件是Telegraf，一个用于收集和发送指标的插件驱动的服务器代理，内存占用小，可以用来定时获取VMware vCenter的虚拟机资源数据。Telegraf拥有插件和集成功能，用于收集系统和服务的各项指标(主要是时间序列数据，比如CPU、MEM)。支持输入输出插件。通过插件系统开发人员可轻松添加支持其他服务的扩展。 输入端可以从以下来源获取指标数据： 直接获取操作系统的指标 从三方api获取指标 通过StatsD、kafka获取指标 输出端可以发送指标数据给以下数据存储： 数据存储db：InfluxDB、OpenTSDB、Graphite、Datadog、Librato、Kafka、MQTT、NSQ 服务 消息队列 常用的输入插件mysql、redis、prometheus等都有。 原理 定时执行输入插件收集数据->执行处理插件和聚合插件->批量输出到存储 cAdvisor Google的监控工具。需要在所有节点安装，用于收集监测单节点容器资源信息。 Prometheus Go语言开发。Prometheus是一套开源的监控&报警&时间序列数据库的组合。 原理 通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控，是比较适合 Docker，Kubernetes 等环境的监控系统之一。输出监控信息的HTTP接口被称作 exporter。可以采用Pull或者Push的方式获取监控指标数据。建议使用的是 Pull 模型，使用Pull方式对监控指标数据从采集服务点(Agent)进行拉取。下图中Prometheus Server 通过 HTTP 的 pull 方式到各个目标拉取监控数据。exporter可以是Redis、Nginx、Node Retrieval：中定义了 Prometheus Server 需要从哪些地方拉取数据 Jobs / Exporters：Prometheus 可以从 Jobs 或 Exporters 中拉取监控数据。Exporter 以 Web API 的形式对外暴露数据采集接口。- **Prometheus Server**：Prometheus 还可以从其他的 Prometheus Server 中拉取数据。 - **Pushgateway**：对于一些以临时性 Job 运行的组件，Prometheus 可能还没有来得及从中 pull 监控数据的情况下，这些 Job 已经结束了，Job 运行时可以在运行时将监控数据推送到 Pushgateway 中，Prometheus 从 Pushgateway 中拉取数据，防止监控数据丢失。 - **Service**：是指 Prometheus 可以动态的发现一些服务，拉取数据进行监控，如从DNS，Kubernetes，Consul 中发现。 Storage：即 Prometheus 的存储，利用 Prometheus Server 的本地存储。 PromQL：是 Prometheus 的查询语句，利用 PromQL 可以和一些 WEBUI (如 Grafana )集成 AlertManager：是一个独立于 Prometheus 的外部组件，用于监控系统的告警，通过配置文件可以配置一些告警规则，Prometheus 会把告警推送到 AlertManager。 存储(时序数据库) InfluxDB TICK STACK中的开源组件。Go语言开发，无依赖。是一个分布式时序、事件和指标数据库,用于处理高写入和查询负载。可以用来收集容器监控数据 OpenTSDB Graphite TimescaleDB 可视化组件 Grafana 监控绘图工具，纯Javascript 开发的前端工具，流行度高。通过多种数据源(如InfluxDB、Prometheus等），作为监控告警的入口，展示自定义报表、显示图表。同Kibana类似，大多使用在时序数据的监控方面。支持的时序数据库有：InfluxDB、OpenTSDB、Graphite、Prometheus、Elasticsearch；支持关系数据库MySQL、PostgreSQL。Go语言开发。自带用户、告警功能。通过配置db数据源展示数据。可以实时收集、存储、显示时间序列类型的数据。 Chronograf Chronograf是TICK STACK中的展示组件Web应用程序。将Chronograf与TICK堆栈的其他组件一起使用，可以显示监控数据并创建警报和自动化规则。 日志监控 felk filebeat(日志采集)、elasticsearch(分布式的存储引擎)、logstash(日志数据做结构化处理)和kibana(监控面板)。市面上成熟的日志监控方案 es的特点：提供了丰富的查询和聚合功能。可以对索引进行生命周期管理，如超过时间范围内的数据进行冷热部署，删除等操作。 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/goal.html":{"url":"architect/goal.html","title":"系统目标","keywords":"","body":"系统目标 线上生产环境如果出现服务故障，如资源使用过载，业务逻辑报错等问题，会直接影响用户正常使用服务。同时，当出现故障时，我们也希望可以快速将错误的告警信息告知运维人员，以保证业务服务的可用性。所以，在线上系统中，监控告警系统是必不可缺的，我们通过监控系统来监控服务的健康状况，业务接口响应时间，关键性能指标等状态。当服务出现问题时可以尽快联系运维人员，保留必要的错误快照信息方便开发人员排障和复盘。 我们系统监控达成的目标是: 对系统不间断监控：监控系统对业务服务系统实时监控，如果产生系统异常及时告警反馈给运维人员。 不同维度的监控：在系统运行的过程中，总是会产生意想不到的问题出现，如网络中断，系统资源使用异常，业务服务逻辑报错等情况，监控系统需要在性能指标，日志信息两个维度进行监控。 完善的告警记录：对所有告警信息进行持久化处理，当运维人员再次上线查看报错信息时，如是性能指标异常导致的告警，可以跟踪到发生异常的具体时间段和告警主体（如是CPU资源使用率异常可以找到什么时间范围内哪个机器产生的错误）。如是具体业务逻辑错误导致的告警，可以查询到触发异常的具体错误日志信息，结合排障手册进行问题分析和复现。 排障闭环：收到了告警信息，运维人员需要结合排障手册对出现的故障进行分析，并及时解决，形成问题发生->问题发生->问题分析->问题解决的完整闭环。 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/design.html":{"url":"architect/design.html","title":"可选架构","keywords":"","body":"可选架构 目前可行方案是先基于当前市面上的开源系统做统一集成。 监控来源区分 应用的不同宿主机采取相应的监控组件 我们可以参考这种设计： 使用telegraf+influxdb用作虚拟机Vmware层指标监控 使用node-exporter + prometheus用作GuestOS层指标监控 使用cadvisor+prometheus用作容器层指标监控 使用kube-state-metrics + prometheus用作k8s层指标监控 系统整体架构设计 监控模块主要将基础性能指标与业务服务日志进行收集和存储（图上基础指标收集与展示面板部分）。VMware层面的基础性能指标通过telegraf服务采集，上报给influxdb。GuestOS层，容器层和kubernetes 资源层性能指标分别通过node-exporter，cadvisor和kube-state-metrics来进行采集，Prometheus通过Pull的方式对数据指标进行获取。业务服务的报错通常以日志的形式进行展现，比如业务服务报错打印错误堆栈信息等，监控系统主要filebeat对业务服务的日志进行采集，并上报给logstash进行日志数据的结构化处理，最终保存到Elasticsearch中。 展示模块以grafana做为监控入口，将数据进行可视化展示，同时可以在grafana上动态设置告警规则。grafana上支持多种数据源的展示，并根据不同的数据源进行聚合查询，在面板上展示具体指标的时序图。grafana根据不同维度集成不同维度的指标面板，方便运维人员对服务运行状态的检查。grafana提供统一的告警列表面板，可展示当前告警信息与告警历史记录。 对于告警信息而言，分为业务服务告警信息和基础性能指标告警信息。业务服务告警信息对业务服务的日志有一定的要求，需要日志格式包含跟踪号Traceid，如一次http请求调用所产生的所有相关日志都应该具有同一Traceid。这样在业务服务发生错误信息告警的时候会根据Traceid链接到Kibana界面中进行相关日志信息的全量查看。对于基础性能监控指标而言，如内存使用率在深夜激增，触发告警，但是在凌晨六点钟内存恢复为正常的状态，告警解除。我们可以在告警历史记录中将这条记录找到，根据告警触发和结束时间可以连接到指定环境进行问题排查。 告警模块是由alertmanager和alertwebhook组成的，alertmanager是Prometheus监控组件中一个开源的告警管理服务，它可以对告警信息进行分组、静默和抑制等操作。alertmanager负责将告警信息转发，可以对接短信，邮箱，webhook等。alertwebhook是自研的一个告警信息管理服务，它会持久化所有告警信息，更新告警状态。 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/apm.html":{"url":"architect/apm.html","title":"APM应用性能管理","keywords":"","body":"APM应用性能管理 数据采集接入配置 业务资源管理 业务规则配置 可视化 统计与分析 告警分析 监控数据分析 对于应用的管理者来说，希望通过简单全面的业务墙能快速发现业务健康问题，通过异常指标快速定位故障实例，通过调用链等实现故障根因定位。另外，对监控数据的指标需要有合理的判断和推算，减少误报，告警和通知明确和精细。 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/alarm.html":{"url":"architect/alarm.html","title":"告警配置","keywords":"","body":"告警配置 告警规则设置 告警模型配置 告警问题分级以及升级管理 告警模版配置 告警发送方式接入 告警事件处理机制：对告警事件的处理可独立成单独的系统，支持过滤、通知、响应、处置、跟踪以及分析，实现事件全生命周期管理，最终提供事件的异常检测、根因分析、智能预测能力。 指标数据分析以及异常检测可能通过大数据和机器学习，自动识别、分级异常数据最终产生告警。 告警规则如何制定 一个告警规则和策略需要包含告警的统计指标、告警推送的条件、告警的时间窗口规则。 例如： 告警名称：网络故障告警 告警指标：网络速度 告警条件：网络速度小于20kb/s 统计时间：30分钟 发生次数：3次 表示：当某台设备30分钟内上报网速小于20kb/s大于等于3次时触发告警 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/display.html":{"url":"architect/display.html","title":"数据可视化","keywords":"","body":"数据可视化 基于数据源和数据表产生的可视化数据需要实现以下功能： 可视化数据库的处理分析流程； 数据的建模分析； 基于采集到的数据的存储、分析以及可视化，可以参考以下数据中台架构图： Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/log.html":{"url":"architect/log.html","title":"日志管理","keywords":"","body":"日志管理 实现离散日志数据的统一采集、处理、检索、模式识别、可视化分析以及智能告警。 基于日志管理的场景可以扩展到： 日志的运维监控与分析 调用链追踪 安全审计 业务分析 数据报表 通过日志得到拓扑的参考图 日志管理的逻辑架构 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "},"architect/managesystem.html":{"url":"architect/managesystem.html","title":"运维平台产品化","keywords":"","body":"运维平台产品化 业务运维平台架构 解决方案逻辑架构 大数据运维管理平台功能架构参考图 Copyright doc.r2ys.life 2021 all right reserved，powered by Gitbook文档修订时间： 2021-06-16 01:30:38 "}}